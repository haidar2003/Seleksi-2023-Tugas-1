{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Muhammad Rafi Haidar\n",
    "\n",
    "Kontak: 18221134@std.stei.itb.ac.id\n",
    "\n",
    "Program untuk melakukan scraping data properti yang dijual di di raywhite.co.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library yang digunakan\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import json\n",
    "import simplejson\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.io.json._json.loads = lambda s, *a, **kw: json.loads(s)\n",
    "pd.io.json._json.loads = lambda s, *a, **kw: simplejson.loads(s)\n",
    "pd.io.json._json.loads = lambda s, *a, **kw: pd.json_normalize(simplejson.loads(s))\n",
    "\n",
    "# URL menuju laman listing\n",
    "URL = 'https://www.raywhite.co.id/jual?tipe={}&order=newest&limit=39&page={}'\n",
    "\n",
    "# XPATH yang dipakai di laman tujuan\n",
    "TITLE_XPATH = '//*[@id=\"detail-sale\"]/div/div/div[1]/div/div/div[1]/h1'\n",
    "LOCATION_XPATH = '//*[@id=\"detail-sale\"]/div/div/div[1]/div/div/div[1]/p[2]'\n",
    "SPEC_XPATH = '//*[@id=\"detail-sale\"]/div/div/div[2]/div[3]/table/tbody/tr[{}]/td[{}]'\n",
    "REALTOR_XPATH = '//*[@id=\"detail-sale\"]/div/div/div[1]/div/div/div[2]/div/h5/a'\n",
    "REALTOR_OFFICE_XPATH = '//*[@id=\"detail-sale\"]/div/div/div[1]/div/div/div[2]/div/div[1]/a'\n",
    "PHONE_XPATH = '//*[@id=\"detail-sale\"]/div/div/div[1]/div/div/div[2]/div/div[2]/a[1]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk scraping\n",
    "\n",
    "# extract_title(lxml.etree._Element tree) -> String\n",
    "# Melakukan scraping judul properti\n",
    "def extract_title(tree):\n",
    "    # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "    title_element = tree.xpath(TITLE_XPATH)[0]\n",
    "    title = title_element.text.strip().replace('\\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t', ' ') if title_element is not None else \"\"\n",
    "\n",
    "    return title\n",
    "\n",
    "# extract_value_usd(Beautifulsoup Soup) -> Int\n",
    "# Melakukan scraping harga properti\n",
    "def extract_value_usd(soup):\n",
    "    price_card = soup.find('div', class_=\"btn-group btn-group-sm\")\n",
    "    value_usd = price_card.find_all('input')[1]['value']\n",
    "    value_usd = value_usd.replace(\",\", \"\")\n",
    "\n",
    "    try:\n",
    "        value_usd = int(value_usd)\n",
    "    except ValueError:\n",
    "        value_usd = 0\n",
    "        \n",
    "    return value_usd\n",
    "\n",
    "# extract_location(lxml.etree._Element tree) -> Tuple of (String, String)\n",
    "# Melakukan scraping lokasi properti\n",
    "def extract_location(tree):\n",
    "    # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "    location_element = tree.xpath(LOCATION_XPATH)[0]\n",
    "    location = location_element.text.strip() if location_element is not None else \"\"\n",
    "    city, province = location.split(\", \")\n",
    "\n",
    "    return (city, province)\n",
    "\n",
    "\n",
    "# extract_realtor_id(Beautifulsoup Soup) -> Int\n",
    "# Melakukan scraping ID agen yang menjual properti\n",
    "def extract_realtor_id(soup):\n",
    "    url_list = soup.find_all('a', href=True)\n",
    "    agent_url = [a['href'] for a in url_list if a['href'].startswith('https://www.raywhite.co.id/agent/')]\n",
    "    try:\n",
    "        id_str = agent_url[0].split('/')[-2]\n",
    "        return int(id_str)\n",
    "    except (IndexError, ValueError):\n",
    "        return 0\n",
    "    \n",
    "\n",
    "# extract_realtor(lxml.etree._Element tree) -> String\n",
    "# Melakukan scraping nama agen yang menjual properti\n",
    "def extract_realtor(tree):\n",
    "    # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "    realtor_element = tree.xpath(REALTOR_XPATH)[0]\n",
    "    \n",
    "    return realtor_element.text.strip() if realtor_element is not None else \"\"\n",
    "\n",
    "# extract_office(lxml.etree._Element tree) -> String\n",
    "# Melakukan scraping kantor agen yang menjual properti\n",
    "def extract_office(tree):\n",
    "    # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "    office_element = tree.xpath(REALTOR_OFFICE_XPATH)[0]\n",
    "\n",
    "    return office_element.text.strip() if office_element is not None else \"\"\n",
    "\n",
    "# extract_negotiable(Beautifulsoup Soup) -> Bool\n",
    "# Melakukan scraping status negosiasi harga properti\n",
    "def extract_negotiable(soup):\n",
    "    value_element = soup.find('p', class_=\"h3 mb-3\").text.strip()\n",
    "    pattern = re.compile(r\"nego\", re.IGNORECASE)\n",
    "    match = re.search(pattern, value_element)\n",
    "\n",
    "    return bool(match)\n",
    "\n",
    "# extract_phone(lxml.etree._Element tree) -> Int\n",
    "# Melakukan scraping nomor kontak agen yang menjual properti\n",
    "def extract_phone(tree):\n",
    "    # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "    phone_element = tree.xpath(PHONE_XPATH)\n",
    "\n",
    "    if phone_element:\n",
    "        href = phone_element[0].get('href')\n",
    "        phone = href.split(':')[1]\n",
    "\n",
    "        # Hanya mengambil nomor pertama\n",
    "        if \"/\" in phone:\n",
    "            phone = phone.split(\"/\")[0]\n",
    "\n",
    "        # Nomor kosong tidak akan diambil\n",
    "        if (phone == \"\") or (len(phone) == 0):\n",
    "            phone = None\n",
    "            \n",
    "    else:\n",
    "        phone = None\n",
    "    \n",
    "    # Formatting nomor telepon\n",
    "    if (phone != None) and (phone[0] != '+'):\n",
    "        phone = '+' + phone\n",
    "\n",
    "    return phone\n",
    "\n",
    "# extract_specification(lxml.etree._Element tree) -> List of any\n",
    "# Melakukan scraping spesifikasi properti\n",
    "def extract_specification(tree):\n",
    "    retval = [None, None, None, None, None, None, None, None]\n",
    "\n",
    "    for i in range(1, 9):\n",
    "        try:\n",
    "            # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "            label_element = tree.xpath(SPEC_XPATH.format(i, 2))[0]\n",
    "            label = label_element.text.strip() if label_element is not None else \"\"\n",
    "        except IndexError:\n",
    "            return retval\n",
    "        \n",
    "        # Mengambil elemen dengan XPATH tertentu di element tree\n",
    "        value_element = tree.xpath(SPEC_XPATH.format(i, 3))[0]\n",
    "        value = value_element.text.strip().replace(\": \", \"\") if value_element is not None else \"\"\n",
    "        \n",
    "        if label == 'Listing ID':\n",
    "            retval[0] = value\n",
    "            # Ubah ke integer\n",
    "            if (retval[0] != None) and (retval[0] != ''):\n",
    "                retval[0] = int(retval[0])\n",
    "        elif label == 'Live ID':\n",
    "            retval[1] = value.replace(\":\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\", \"\")\n",
    "        elif label == 'Building Size':\n",
    "            retval[2] = value.replace(\" m\", \"\")\n",
    "            # Ubah ke integer\n",
    "            if (retval[2] != None) and (retval[2] != ''):\n",
    "                retval[2] = int(retval[2])\n",
    "        elif label == 'Land Size':\n",
    "            retval[3] = value.replace(\" m\", \"\")\n",
    "            # Ubah ke integer\n",
    "            if (retval[3] != None) and (retval[3] != ''):\n",
    "                retval[3] = int(retval[3])\n",
    "        elif label == 'Certificate':\n",
    "            retval[4] = value\n",
    "        elif label == 'Bedroom':\n",
    "            retval[5] = value\n",
    "            # Ubah ke integer\n",
    "            if (retval[5] != None) and (retval[5] != ''):\n",
    "                retval[5] = int(retval[5])\n",
    "        elif label == 'Bathroom':\n",
    "            retval[6] = value\n",
    "            # Ubah ke integer\n",
    "            if (retval[6] != None) and (retval[6] != ''):\n",
    "                retval[6] = int(retval[6])\n",
    "        elif label == 'Carport':\n",
    "            retval[7] = value\n",
    "            # Ubah ke integer\n",
    "            if (retval[7] != None) and (retval[7] != ''):\n",
    "                retval[7] = int(retval[7])\n",
    "\n",
    "    return retval\n",
    "\n",
    "# extract(lxml.etree._Element tree, Beautifulsoup soup, String type) -> Dictionary\n",
    "# Melakukan scraping properti\n",
    "def extract_property(tree, soup, propertyType):\n",
    "    title = extract_title(tree)\n",
    "    location = extract_location(tree)\n",
    "    value_usd = extract_value_usd(soup)\n",
    "    realtor_id = extract_realtor_id(soup)\n",
    "    realtor = extract_realtor(tree)\n",
    "    office = extract_office(tree) \n",
    "    negotiable = extract_negotiable(soup)\n",
    "    phone = extract_phone(tree)\n",
    "    specification = extract_specification(tree)\n",
    "\n",
    "    return {\n",
    "                'listing_id': specification[0], #0\n",
    "                'live_id': specification[1], #1\n",
    "                'type': propertyType.lower(), #2\n",
    "                'title': title, #3\n",
    "                'province': location[1], #4\n",
    "                'city': location[0], #5\n",
    "                'value_usd': value_usd, #6\n",
    "                'value_idr': value_usd * 15068, #7\n",
    "                'negotiable': negotiable, #8\n",
    "                'building_size': specification[2], #9\n",
    "                'land_size': specification[3], #10\n",
    "                'certificate': specification[4], #11\n",
    "                'bedroom': specification[5], #12\n",
    "                'bathroom': specification[6], #13\n",
    "                'carport': specification[7], #14\n",
    "                'realtor_id': realtor_id, #15\n",
    "                'realtor': realtor, #16\n",
    "                'realtor_phone': phone, #17\n",
    "                'realtor_office': office #18\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi lainnya\n",
    "\n",
    "# save_to_csv(pd.DataFrame dataframe, String propertyType, Int documentCounter)\n",
    "# Membuat berkas CSV untuk mencatat kemajuan proses scraping per properti\n",
    "def save_to_csv(dataframe, propertyType, documentCounter):\n",
    "    output_dir = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\src\\csv'\n",
    "    csv_filename = os.path.join(output_dir, f'raywhite_{propertyType.lower()}_{documentCounter}.csv')\n",
    "    dataframe.to_csv(csv_filename, index=False)\n",
    "\n",
    "# save_to_json(pd.DataFrame dataframe, String propertyType, Int documentCounter)\n",
    "# Membuat berkas JSON untuk mencatat kemajuan proses scraping per properti\n",
    "def save_to_json(dataframe, propertyType, documentCounter):\n",
    "    output_dir = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data'\n",
    "    json_filename = os.path.join(output_dir, f'raywhite_{propertyType.lower()}_{documentCounter}.json')\n",
    "    dataframe.to_json(json_filename, orient='records')\n",
    "\n",
    "# filter(Dictionary entry) -> Boolea\n",
    "# Melakukan proses filtering untuk memastikan entry bersifat valid\n",
    "def filter(entry):\n",
    "    conditions = [\n",
    "        entry['listing_id'] != None and entry['listing_id'] != '', # Listing ID harus ada\n",
    "        entry['title'] != '' and entry['title'] != None, # Judul properti harus ada dan bukan empty string\n",
    "        entry['province'] != '' and entry['province'] != None, # Provinsi dari lokasi properti harus ada dan bukan empty string\n",
    "        entry['city'] != '' and entry['city'] != None, # Kota dari lokasi properti harus ada dan bukan empty string\n",
    "        entry['value_usd'] > 0, # Harga properti harus lebih dari 0 USD\n",
    "        entry['negotiable'] != None, # Status negosiasi properti harus jelas \n",
    "        entry['certificate'] != None, # Sertifikat properti harus ada\n",
    "        entry['realtor_id'] != 0, # ID agen properti harus ada\n",
    "        entry['realtor'] != '' and entry['realtor'] != None, # Nama agen properti harus ada dan bukan empty string\n",
    "        entry['realtor_phone'] != None, # Agen properti harus mempunyai nomor telepon\n",
    "        entry['realtor_office'] != '' and entry['realtor_office'] != None # Kantor agen properti harus ada dan bukan empty string\n",
    "    ]\n",
    "\n",
    "    return all(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melakukan scraping pada tipe properti House\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                     | 585/11700 [02:04<19:51,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_1.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▊                                  | 1170/11700 [03:37<18:32,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_2.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▋                                | 1755/11700 [05:28<18:38,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_3.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▌                              | 2339/11700 [07:11<17:58,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_4.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████▌                            | 2925/11700 [08:43<15:19,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_5.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▍                          | 3510/11700 [10:08<19:35,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_6.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████▎                        | 4094/11700 [11:27<11:58, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_7.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▏                      | 4680/11700 [12:54<12:24,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_8.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████                     | 5264/11700 [14:22<12:00,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_9.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████▉                   | 5849/11700 [15:49<11:30,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_10.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████▉                 | 6435/11700 [17:34<27:29,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_11.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████▊               | 7020/11700 [18:58<07:31, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_12.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████▋             | 7605/11700 [20:24<08:22,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_13.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████▌           | 8190/11700 [21:46<05:33, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_14.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████▌         | 8775/11700 [23:13<08:20,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_15.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████▍       | 9359/11700 [24:36<04:25,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_16.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████▎     | 9945/11700 [26:26<04:21,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_17.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████▎   | 10530/11700 [28:26<03:06,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_18.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████▏ | 11115/11700 [30:28<03:07,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_19.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 11700/11700 [32:34<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_20.[json|csv]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Melakukan scraping pada tipe properti Office\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 585/585 [01:39<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti Office telah diubah menjadi dataframe cadangan dan disimpan di raywhite_Office_1.[json|csv]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Melakukan scraping pada tipe properti Shophouse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 585/585 [01:39<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti Shophouse telah diubah menjadi dataframe cadangan dan disimpan di raywhite_Shophouse_1.[json|csv]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Melakukan scraping pada tipe properti Villa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 585/585 [01:36<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti Villa telah diubah menjadi dataframe cadangan dan disimpan di raywhite_Villa_1.[json|csv]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Melakukan scraping pada tipe properti Warehouse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 585/585 [01:39<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti Warehouse telah diubah menjadi dataframe cadangan dan disimpan di raywhite_Warehouse_1.[json|csv]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Proses scraping telah selesai!\n",
      "\n",
      "Dokumentasi:\n",
      "Banyak entry yang di-scrape:  14040\n",
      "Banyak entry valid valid di dataframe akhir:  9697\n",
      "Persentase entry yang valid: 69.06695156695156%\n",
      "\n",
      "Hasil scraping telah diubah menjadi dataframe dan disimpan di:\n",
      "C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\src\\csv\\raywhite_merged.csv\n",
      "C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data\\raywhite_merged.json\n",
      "\n",
      "Dataframe gabungan:\n",
      "\n",
      "      listing_id       type  \\\n",
      "0         395345      house   \n",
      "1         395344      house   \n",
      "2         395342      house   \n",
      "3         395338      house   \n",
      "4         395337      house   \n",
      "...          ...        ...   \n",
      "9764      367059  warehouse   \n",
      "9765      367089  warehouse   \n",
      "9766      366947  warehouse   \n",
      "9767      366948  warehouse   \n",
      "9768      366865  warehouse   \n",
      "\n",
      "                                                  title     province  \\\n",
      "0      Rumah Siap Huni dan Hunian Nyaman @Graha Bintaro  DKI Jakarta   \n",
      "1      Rumah Siap Huni dan Hunian Nyaman @Graha Bintaro  DKI Jakarta   \n",
      "2     Rumah Bagus Siap Huni di Fajar Raya Estate, Ci...   Jawa Barat   \n",
      "3     Rumah Minimalis Siap Huni dan Lokasi Strategis...       Banten   \n",
      "4     Rumah Minimalis Siap Huni dan Lokasi Strategis...       Banten   \n",
      "...                                                 ...          ...   \n",
      "9764                  Gudang Bagus 2 lantai di Matraman  DKI Jakarta   \n",
      "9765              Ruko Trace, Ruko Ramai Depan Al Azhar   Jawa Barat   \n",
      "9766      Gudang Cocok Untuk Workshop Di Cikalong Wetan   Jawa Barat   \n",
      "9767      Gudang Cocok Untuk Workshop Di Cikalong Wetan   Jawa Barat   \n",
      "9768                       RUKO DI JL MAGELANG 3 LANTAI   Yogyakarta   \n",
      "\n",
      "                 city  value_usd    value_idr  negotiable    live_id  \\\n",
      "0     Jakarta Selatan     123003   1853409204       False  L23328094   \n",
      "1     Jakarta Selatan     123003   1853409204       False  L23328083   \n",
      "2             Bandung     179518   2704977224        True  L23328069   \n",
      "3           Tangerang      86434   1302387512       False  L23328056   \n",
      "4           Tangerang      86434   1302387512       False  L23328052   \n",
      "...               ...        ...          ...         ...        ...   \n",
      "9764    Jakarta Timur     997321  15027632828        True  L20097799   \n",
      "9765           Bekasi      86434   1302387512       False  L20099798   \n",
      "9766          Bandung     365684   5510126512       False  L20046871   \n",
      "9767          Bandung     365684   5510126512       False  L20046920   \n",
      "9768       Yogyakarta     312494   4708659592       False  L20002852   \n",
      "\n",
      "      building_size  land_size   certificate  bedroom  bathroom  carport  \\\n",
      "0             250.0       84.0  SHM/Freehold      4.0       3.0      1.0   \n",
      "1             250.0       84.0  SHM/Freehold      4.0       3.0      1.0   \n",
      "2             200.0      320.0  SHM/Freehold      3.0       2.0      1.0   \n",
      "3             144.0       72.0           HGB      3.0       2.0      1.0   \n",
      "4             144.0       72.0           HGB      3.0       2.0      1.0   \n",
      "...             ...        ...           ...      ...       ...      ...   \n",
      "9764         1400.0      859.0  SHM/Freehold      NaN       NaN      NaN   \n",
      "9765           80.0       40.0           HGB      NaN       NaN      NaN   \n",
      "9766            NaN     5148.0  SHM/Freehold      NaN       NaN      NaN   \n",
      "9767            NaN     5148.0  SHM/Freehold      NaN       NaN      NaN   \n",
      "9768          244.0      106.0  SHM/Freehold      NaN       NaN      NaN   \n",
      "\n",
      "                  realtor                  realtor_office         contact  \n",
      "0        Hanifah Titisari  Ray White Bintaro Trade Center   +628119990796  \n",
      "1         Devy Kurniasari  Ray White Bintaro Trade Center  +6281312112140  \n",
      "2             Ayu Hamidah        Ray White Juanda Bandung  +6282315732016  \n",
      "3         Devy Kurniasari  Ray White Bintaro Trade Center  +6281312112140  \n",
      "4        Hanifah Titisari  Ray White Bintaro Trade Center   +628119990796  \n",
      "...                   ...                             ...             ...  \n",
      "9764       Kuncoro Widodo               Ray White Menteng  +6281345268155  \n",
      "9765  Wahyu Putra Pribadi              Ray White Cikarang  +6281219135665  \n",
      "9766        Christian Shu              Ray White Sukajadi  +6281222122618  \n",
      "9767        Christian Shu              Ray White Sukajadi  +6281222122618  \n",
      "9768               ANNA P         Ray White Central Jogja  +6281514220380  \n",
      "\n",
      "[9698 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "# Program Utama\n",
    "\n",
    "# -------- PENTING --------\n",
    "# -  1 PAGE  = 39 ENTRY   -\n",
    "# -  1 JSON  = 15 PAGE    -\n",
    "# -  1 JSON  = 585 ENTRY  -\n",
    "# -------------------------\n",
    "\n",
    "# JSON cadangan akan dibuat setiap 585 entry (15 main page) telah di-parse pada tipe properti tertentu untuk redundancy dan memastikan kemajuan tetap tercatat walaupun terjadi kegagalan\n",
    "# JSON yang dimaksud di bawah adalah JSON cadangan, JSON gabungan akan tetap dibuat saat program berakhir\n",
    "# CSV backup dan gabungan akan dibuat untuk redundancy\n",
    "PAGE_PER_JSON = 15\n",
    "\n",
    "# Entries on raywhite.co.id as of 01/07/2023:\n",
    "# [0] Apartment = 8524 - 14 JSON can be extracted\n",
    "# [1] Commercial = 9925 - 19 JSON can be extracted\n",
    "# [2] Factory = 647 - 1 JSON can be extracted\n",
    "# [3] House = 80798 - 138 JSON can be extracted\n",
    "# [4] Office = 704 - 1 JSON can be extracted\n",
    "# [5] Shophouse = 3856 - 6 JSON can be extracted\n",
    "# [6] Villa = 1288 - 2 JSON can be extracted\n",
    "# [7] Warehouse = 2824 - 4 JSON can be extracted\n",
    "\n",
    "# Jumlah JSON cadangan yang ingin di scrape dari setiap tipe properti\n",
    "APPARTMENT = 2\n",
    "COMMERCIAL = 2\n",
    "FACTORY = 1\n",
    "HOUSE = 20\n",
    "OFFICE = 1\n",
    "SHOPHOUSE = 1\n",
    "VILLA = 1\n",
    "WAREHOUSE = 1\n",
    "\n",
    "# Tipe properti yang ingin di-scrape (tanah belum tersedia saat ini)\n",
    "PROPERTY_TYPE = ('Apartment', 'Commercial', 'Factory', 'House', 'Office', 'Shophouse', 'Villa', 'Warehouse')\n",
    "SCRAPING_TARGET = (APPARTMENT, COMMERCIAL, FACTORY, HOUSE, OFFICE, SHOPHOUSE, VILLA, WAREHOUSE)\n",
    "\n",
    "# Untuk ethical scraping\n",
    "# Nama menggunakan alias untuk alasan keamanan dan kerahasiaan\n",
    "# Alamat email yang tercantum bukan alamat email pribadi ataupun alamat email instansi untuk alasan keamanan dan kerahasiaan\n",
    "# Pemilik website tetap dapat menggunakan alamat email tersebut untuk menghubungi penulis\n",
    "HEADER = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.199 Safari/537.36',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Name': 'Campus Fox',\n",
    "    'Email': 'rubahkampus@protonmail.com'\n",
    "}\n",
    "\n",
    "# List Akhir\n",
    "final_list = []\n",
    "\n",
    "# Counter Akhir Untuk Dokumentasi\n",
    "main_page_counter = 0\n",
    "\n",
    "for propertyType in range(0, len(PROPERTY_TYPE)):\n",
    "    print(f'Melakukan scraping pada tipe properti {PROPERTY_TYPE[propertyType]}')\n",
    "\n",
    "    pageParsed = SCRAPING_TARGET[propertyType] * PAGE_PER_JSON\n",
    "\n",
    "    # List Sementara\n",
    "    temp_list = []\n",
    "\n",
    "    # Counter Sementara\n",
    "    entry_counter = 0\n",
    "    document_counter = 1\n",
    "\n",
    "    # Progress Bar Agar Kemajuan Mudah Dilihat Mata\n",
    "    pbar = tqdm(total=pageParsed*39, ncols=80)\n",
    "\n",
    "    for page in range(1, pageParsed+1):\n",
    "        main_page_counter += 1\n",
    "        main_response = requests.get(URL.format(PROPERTY_TYPE[propertyType], page), headers=HEADER)\n",
    "        \n",
    "        if main_response.status_code == 200:\n",
    "            main_content = main_response.text\n",
    "            main_soup = BeautifulSoup(main_content, 'html.parser')\n",
    "\n",
    "            url_list = main_soup.find_all('a', href=True)\n",
    "            house_url = [a['href'] for a in url_list if a['href'].startswith('https://www.raywhite.co.id/properti/')]\n",
    "\n",
    "            for house in house_url:\n",
    "                house_response = requests.get(house, headers=HEADER)\n",
    "                if house_response.status_code == 200:\n",
    "                    house_content = house_response.content\n",
    "\n",
    "                    house_soup = BeautifulSoup(house_content, 'html.parser')\n",
    "                    xml_parsed = etree.HTML(str(house_soup))\n",
    "                    \n",
    "                    house_item = extract_property(xml_parsed, house_soup, PROPERTY_TYPE[propertyType])\n",
    "\n",
    "                    # Cek validitas entry\n",
    "                    if filter(house_item):\n",
    "                        temp_list.append(house_item)\n",
    "                        final_list.append(house_item)\n",
    "\n",
    "                    entry_counter += 1\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "\n",
    "                    if entry_counter % 585 == 0:  \n",
    "                        df = pd.DataFrame(temp_list).drop_duplicates()\n",
    "                        save_to_json(df, PROPERTY_TYPE[propertyType], document_counter)\n",
    "                        save_to_csv(df, PROPERTY_TYPE[propertyType], document_counter) # Untuk redundancy\n",
    "                        print(f'Kemajuan scraping pada tipe properti {PROPERTY_TYPE[propertyType]} telah diubah menjadi dataframe cadangan dan disimpan di raywhite_{PROPERTY_TYPE[propertyType]}_{document_counter}.[json|csv]')\n",
    "\n",
    "                        entry_counter = 0\n",
    "                        document_counter += 1\n",
    "                        temp_list = []\n",
    "                \n",
    "                else:\n",
    "                    print('Koneksi Gagal')\n",
    "\n",
    "        else:\n",
    "            print('Koneksi Gagal')\n",
    "\n",
    "    pbar.close()\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "\n",
    "if len(temp_list) > 0:\n",
    "    df = pd.DataFrame(temp_list).drop_duplicates()\n",
    "    save_to_json(df, PROPERTY_TYPE[propertyType], document_counter)\n",
    "    save_to_csv(df, PROPERTY_TYPE[propertyType], document_counter) # Untuk redundancy\n",
    "\n",
    "\n",
    "# Pembuatan JSON dan CSV gabungan\n",
    "df_final = pd.DataFrame(final_list).drop_duplicates()\n",
    "\n",
    "output_dir_json = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data'\n",
    "output_dir_csv = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\src\\csv'\n",
    "\n",
    "csv_filename = os.path.join(output_dir_csv, f'raywhite_merged.csv')\n",
    "json_filename = os.path.join(output_dir_json, f'raywhite_merged.json')\n",
    "\n",
    "df_final.to_csv(csv_filename, index=False)\n",
    "df_final.to_json(json_filename, orient='records')\n",
    "\n",
    "print('Proses scraping telah selesai!\\n')\n",
    "\n",
    "print(f'Dokumentasi:')\n",
    "print('Banyak entry yang di-scrape: ', main_page_counter * 39)\n",
    "print('Banyak entry valid valid di dataframe akhir: ', len(df_final) - 1)\n",
    "print('Persentase entry yang valid: '+str(((len(df_final) - 1) / (main_page_counter * 39)) * 100)+'%')\n",
    "\n",
    "print(f\"\\nHasil scraping telah diubah menjadi dataframe dan disimpan di:\\n{csv_filename}\\n{json_filename}\\n\")\n",
    "\n",
    "print('Dataframe gabungan:\\n')\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me-reset progress bar\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melakukan scraping pada tipe properti House\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                     | 585/11700 [01:36<31:13,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_1.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▊                                  | 1170/11700 [03:23<31:00,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_2.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▋                                | 1755/11700 [04:47<17:38,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_3.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▌                              | 2340/11700 [06:31<26:06,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_4.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████▌                            | 2925/11700 [08:10<18:43,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_5.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▍                          | 3510/11700 [10:13<29:35,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_6.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████▎                        | 4094/11700 [11:55<13:12,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_7.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▏                      | 4680/11700 [13:44<17:42,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_8.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████                     | 5265/11700 [15:58<13:14,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_9.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████                   | 5850/11700 [17:43<12:11,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_10.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████▉                 | 6435/11700 [19:21<08:29, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_11.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████▊               | 7020/11700 [21:14<12:19,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_12.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████▋             | 7605/11700 [22:57<37:15,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_13.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████▌           | 8190/11700 [24:33<06:47,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_14.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████▌         | 8775/11700 [26:16<05:11,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_15.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████▍       | 9360/11700 [27:33<05:25,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_16.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████▎     | 9944/11700 [28:54<03:05,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_17.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████▎   | 10530/11700 [30:41<02:03,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_18.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████▏ | 11114/11700 [32:07<01:06,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_19.[json|csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 11700/11700 [33:39<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kemajuan scraping pada tipe properti House telah diubah menjadi dataframe cadangan dan disimpan di raywhite_House_20.[json|csv]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Proses scraping telah selesai!\n",
      "\n",
      "Dokumentasi:\n",
      "Banyak entry yang di-scrape:  11700\n",
      "Banyak entry valid valid di dataframe akhir:  8465\n",
      "Persentase entry yang valid: 72.35042735042735%\n",
      "\n",
      "Hasil scraping telah diubah menjadi dataframe dan disimpan di:\n",
      "C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\src\\csv\\raywhite_merged.csv\n",
      "C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data\\raywhite_merged.json\n",
      "\n",
      "Dataframe gabungan:\n",
      "\n",
      "      listing_id    live_id   type  \\\n",
      "0         396547  L23431882  house   \n",
      "1         396545  L23431879  house   \n",
      "2         396546  L23431880  house   \n",
      "3         396525  L23431366  house   \n",
      "4         396542  L23431782  house   \n",
      "...          ...        ...    ...   \n",
      "8515      373091  L20993745  house   \n",
      "8516      373054  L20992531  house   \n",
      "8517      373036  L20992138  house   \n",
      "8518      373018  L20990624  house   \n",
      "8519      373061  L20992751  house   \n",
      "\n",
      "                                                  title     province  \\\n",
      "0     Rumah Lama di Cilandak Barat Dijual Segera Neg...  DKI Jakarta   \n",
      "1              Jual Rumah Bersalin di Caringin, Bandung   Jawa Barat   \n",
      "2     Dijual Segera Rumah di Jatipadang Pasar Minggu...  DKI Jakarta   \n",
      "3         Rumah di Kebayoran Residence Bintaro Sektor 7       Banten   \n",
      "4     Rumah Murah dan Bagus di Jakarta Garden City C...  DKI Jakarta   \n",
      "...                                                 ...          ...   \n",
      "8515  Rumah Siap Huni Minimalis dalam Cluster @Urban...       Banten   \n",
      "8516  Dijual Rumah di Jalan Sam Ratulangi, Surabaya ...   Jawa Timur   \n",
      "8517  Dijual Rumah Siap Huni di Medokan Asri Utara S...   Jawa Timur   \n",
      "8518  Rumah Villa Permata Gading Kelapa Gading Luas ...  DKI Jakarta   \n",
      "8519  Rumah Raya Pelepah Indah, Kelapa Gading Luas 1...  DKI Jakarta   \n",
      "\n",
      "                   city  value_usd    value_idr  negotiable  building_size  \\\n",
      "0       Jakarta Selatan     726456  10946239008        True          500.0   \n",
      "1               Bandung     422665   6368716220        True          150.0   \n",
      "2       Jakarta Selatan      99062   1492666216        True          196.0   \n",
      "3     Tangerang Selatan     587769   8856503292       False          350.0   \n",
      "4         Jakarta Timur     175010   2637050680        True            NaN   \n",
      "...                 ...        ...          ...         ...            ...   \n",
      "8515  Tangerang Selatan      75948   1144384464       False          105.0   \n",
      "8516           Surabaya     858539  12936465652        True          480.0   \n",
      "8517           Surabaya     198124   2985332432        True          280.0   \n",
      "8518      Jakarta Utara     640602   9652590936       False          366.0   \n",
      "8519      Jakarta Utara     544842   8209679256       False          300.0   \n",
      "\n",
      "      land_size   certificate  bedroom  bathroom  carport  realtor_id  \\\n",
      "0         353.0  SHM/Freehold     48.0       3.0      NaN       26104   \n",
      "1         358.0  SHM/Freehold      9.0       3.0      3.0       20979   \n",
      "2          98.0  SHM/Freehold     39.0       2.0      NaN       26104   \n",
      "3         323.0  SHM/Freehold      7.0       4.0      NaN         852   \n",
      "4           NaN  SHM/Freehold      5.0       4.0      2.0       22574   \n",
      "...         ...           ...      ...       ...      ...         ...   \n",
      "8515       84.0  SHM/Freehold      3.0       2.0      1.0       23098   \n",
      "8516      556.0  SHM/Freehold      4.0       2.0      NaN       20901   \n",
      "8517      250.0  SHM/Freehold      5.0       5.0      NaN       20901   \n",
      "8518      407.0  SHM/Freehold      4.0       3.0      NaN       20525   \n",
      "8519      231.0  SHM/Freehold      3.0       2.0      NaN       20525   \n",
      "\n",
      "                  realtor   realtor_phone                    realtor_office  \n",
      "0            Reni S Urini  +6281399333081                 Ray White Menteng  \n",
      "1             Ayu Hamidah  +6282315732016          Ray White Juanda Bandung  \n",
      "2            Reni S Urini  +6281399333081                 Ray White Menteng  \n",
      "3           Nita Harianti  +6281381595128        Ray White Bintaro Jaya III  \n",
      "4               Nita Chen  +6282210001142  Ray White Prestige Kelapa Gading  \n",
      "...                   ...             ...                               ...  \n",
      "8515  Admin Ray White BTC  +6281324636867    Ray White Bintaro Trade Center  \n",
      "8516        Mei Ray White  +6281335701711     Ray White Diponegoro Surabaya  \n",
      "8517        Mei Ray White  +6281335701711     Ray White Diponegoro Surabaya  \n",
      "8518        Briegita RWKG  +6287881648777           Ray White Kelapa Gading  \n",
      "8519        Briegita RWKG  +6287881648777           Ray White Kelapa Gading  \n",
      "\n",
      "[8466 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# Program Utama\n",
    "\n",
    "# -------- PENTING --------\n",
    "# -  1 PAGE  = 39 ENTRY   -\n",
    "# -  1 JSON  = 15 PAGE    -\n",
    "# -  1 JSON  = 585 ENTRY  -\n",
    "# -------------------------\n",
    "\n",
    "# JSON cadangan akan dibuat setiap 585 entry (15 main page) telah di-parse pada tipe properti tertentu untuk redundancy dan memastikan kemajuan tetap tercatat walaupun terjadi kegagalan\n",
    "# JSON yang dimaksud di bawah adalah JSON cadangan, JSON gabungan akan tetap dibuat saat program berakhir\n",
    "# CSV backup dan gabungan akan dibuat untuk redundancy\n",
    "PAGE_PER_JSON = 15\n",
    "\n",
    "# Entries on raywhite.co.id as of 01/07/2023:\n",
    "# [0] Apartment = 8524 - 14 JSON can be extracted\n",
    "# [1] Commercial = 9925 - 19 JSON can be extracted\n",
    "# [2] Factory = 647 - 1 JSON can be extracted\n",
    "# [3] House = 80798 - 138 JSON can be extracted\n",
    "# [4] Office = 704 - 1 JSON can be extracted\n",
    "# [5] Shophouse = 3856 - 6 JSON can be extracted\n",
    "# [6] Villa = 1288 - 2 JSON can be extracted\n",
    "# [7] Warehouse = 2824 - 4 JSON can be extracted\n",
    "\n",
    "# Jumlah JSON cadangan yang ingin di scrape dari setiap tipe properti\n",
    "APPARTMENT = 2\n",
    "COMMERCIAL = 2\n",
    "FACTORY = 1\n",
    "HOUSE = 20\n",
    "OFFICE = 1\n",
    "SHOPHOUSE = 1\n",
    "VILLA = 1\n",
    "WAREHOUSE = 1\n",
    "\n",
    "# Tipe properti yang ingin di-scrape (tanah belum tersedia saat ini)\n",
    "PROPERTY_TYPE = ('Apartment', 'Commercial', 'Factory', 'House', 'Office', 'Shophouse', 'Villa', 'Warehouse')\n",
    "SCRAPING_TARGET = (APPARTMENT, COMMERCIAL, FACTORY, HOUSE, OFFICE, SHOPHOUSE, VILLA, WAREHOUSE)\n",
    "\n",
    "# Untuk ethical scraping\n",
    "# Nama menggunakan alias untuk alasan keamanan dan kerahasiaan\n",
    "# Alamat email yang tercantum bukan alamat email pribadi ataupun alamat email instansi untuk alasan keamanan dan kerahasiaan\n",
    "# Pemilik website tetap dapat menggunakan alamat email tersebut untuk menghubungi penulis\n",
    "HEADER = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.199 Safari/537.36',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Name': 'Campus Fox',\n",
    "    'Email': 'rubahkampus@protonmail.com'\n",
    "}\n",
    "\n",
    "# List Akhir\n",
    "final_list = []\n",
    "\n",
    "# Counter Akhir Untuk Dokumentasi\n",
    "main_page_counter = 0\n",
    "\n",
    "for propertyType in range(4, len(PROPERTY_TYPE)):\n",
    "    print(f'Melakukan scraping pada tipe properti {PROPERTY_TYPE[propertyType]}')\n",
    "\n",
    "    pageParsed = SCRAPING_TARGET[propertyType] * PAGE_PER_JSON\n",
    "\n",
    "    # List Sementara\n",
    "    temp_list = []\n",
    "\n",
    "    # Counter Sementara\n",
    "    entry_counter = 0\n",
    "    document_counter = 1\n",
    "\n",
    "    # Progress Bar Agar Kemajuan Mudah Dilihat Mata\n",
    "    pbar = tqdm(total=pageParsed*39, ncols=80)\n",
    "\n",
    "    for page in range(1, pageParsed+1):\n",
    "        main_page_counter += 1\n",
    "        main_response = requests.get(URL.format(PROPERTY_TYPE[propertyType], page), headers=HEADER)\n",
    "        \n",
    "        if main_response.status_code == 200:\n",
    "            main_content = main_response.text\n",
    "            main_soup = BeautifulSoup(main_content, 'html.parser')\n",
    "\n",
    "            url_list = main_soup.find_all('a', href=True)\n",
    "            property_url = [a['href'] for a in url_list if a['href'].startswith('https://www.raywhite.co.id/properti/')]\n",
    "\n",
    "            for property in property_url:\n",
    "                property_response = requests.get(property, headers=HEADER)\n",
    "                if property_response.status_code == 200:\n",
    "                    property_content = property_response.content\n",
    "\n",
    "                    property_soup = BeautifulSoup(property_content, 'html.parser')\n",
    "                    xml_parsed = etree.HTML(str(property_soup))\n",
    "                    \n",
    "                    property_item = extract_property(xml_parsed, property_soup, PROPERTY_TYPE[propertyType])\n",
    "\n",
    "                    # Cek validitas entry\n",
    "                    if filter(property_item):\n",
    "                        temp_list.append(property_item)\n",
    "                        final_list.append(property_item)\n",
    "\n",
    "                    entry_counter += 1\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "\n",
    "                    if entry_counter % 585 == 0:  \n",
    "                        df = pd.DataFrame(temp_list).drop_duplicates()\n",
    "                        save_to_json(df, PROPERTY_TYPE[propertyType], document_counter)\n",
    "                        save_to_csv(df, PROPERTY_TYPE[propertyType], document_counter) # Untuk redundancy\n",
    "                        print(f'Kemajuan scraping pada tipe properti {PROPERTY_TYPE[propertyType]} telah diubah menjadi dataframe cadangan dan disimpan di raywhite_{PROPERTY_TYPE[propertyType]}_{document_counter}.[json|csv]')\n",
    "\n",
    "                        entry_counter = 0\n",
    "                        document_counter += 1\n",
    "                        temp_list = []\n",
    "                \n",
    "                else:\n",
    "                    print('Koneksi Gagal')\n",
    "\n",
    "        else:\n",
    "            print('Koneksi Gagal')\n",
    "\n",
    "    pbar.close()\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "\n",
    "if len(temp_list) > 0:\n",
    "    df = pd.DataFrame(temp_list).drop_duplicates()\n",
    "    save_to_json(df, PROPERTY_TYPE[propertyType], document_counter)\n",
    "    save_to_csv(df, PROPERTY_TYPE[propertyType], document_counter) # Untuk redundancy\n",
    "\n",
    "\n",
    "# Pembuatan JSON dan CSV gabungan\n",
    "df_final = pd.DataFrame(final_list).drop_duplicates()\n",
    "\n",
    "output_dir_json = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data'\n",
    "output_dir_csv = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\src\\csv'\n",
    "\n",
    "csv_filename = os.path.join(output_dir_csv, f'raywhite_merged.csv')\n",
    "json_filename = os.path.join(output_dir_json, f'raywhite_merged.json')\n",
    "\n",
    "df_final.to_csv(csv_filename, index=False)\n",
    "df_final.to_json(json_filename, orient='records')\n",
    "\n",
    "print('Proses scraping telah selesai!\\n')\n",
    "\n",
    "print(f'Dokumentasi:')\n",
    "print('Banyak entry yang di-scrape: ', main_page_counter * 39)\n",
    "print('Banyak entry valid valid di dataframe akhir: ', len(df_final) - 1)\n",
    "print('Persentase entry yang valid: '+str(((len(df_final) - 1) / (main_page_counter * 39)) * 100)+'%')\n",
    "\n",
    "print(f\"\\nHasil scraping telah diubah menjadi dataframe dan disimpan di:\\n{csv_filename}\\n{json_filename}\\n\")\n",
    "\n",
    "print('Dataframe gabungan:\\n')\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses merging JSON telah selesai!\n",
      "\n",
      "Dokumentasi:\n",
      "Banyak JSON cadangan yang dihasilkan:  29\n",
      "Banyak entry valid valid di dataframe akhir:  10946\n",
      "Persentase entry yang valid: 64.52107279693486%\n",
      "\n",
      "Hasil scraping telah diubah menjadi dataframe dan disimpan di:\n",
      "C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\src\\csv\\raywhite_merged.csv\n",
      "C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data\\raywhite_merged.json\n",
      "\n",
      "Dataframe gabungan:\n",
      "\n",
      "       listing_id       type  \\\n",
      "0          395340  apartment   \n",
      "1          395334  apartment   \n",
      "2          395306  apartment   \n",
      "3          395209  apartment   \n",
      "4          395251  apartment   \n",
      "...           ...        ...   \n",
      "10944      367059  warehouse   \n",
      "10945      367089  warehouse   \n",
      "10946      366947  warehouse   \n",
      "10947      366948  warehouse   \n",
      "10948      366865  warehouse   \n",
      "\n",
      "                                                   title     province  \\\n",
      "0      Apartemen Siap Huni dan Fasilitas Lengkap @Apa...       Banten   \n",
      "1      Dijual Apartemen Siap Huni, Lokasi Strategis @...       Banten   \n",
      "2                    APARTEMEN TRIVIUM FURNITURE LENGKAP   Jawa Barat   \n",
      "3      For Sale Leasehold - Brand new apartment 1 bed...         Bali   \n",
      "4           The Aspen Residences Fatmawati 3BR Nice View  DKI Jakarta   \n",
      "...                                                  ...          ...   \n",
      "10944                  Gudang Bagus 2 lantai di Matraman  DKI Jakarta   \n",
      "10945              Ruko Trace, Ruko Ramai Depan Al Azhar   Jawa Barat   \n",
      "10946      Gudang Cocok Untuk Workshop Di Cikalong Wetan   Jawa Barat   \n",
      "10947      Gudang Cocok Untuk Workshop Di Cikalong Wetan   Jawa Barat   \n",
      "10948                       RUKO DI JL MAGELANG 3 LANTAI   Yogyakarta   \n",
      "\n",
      "                  city  value_usd     value_idr  negotiable    live_id  \\\n",
      "0            Tangerang    53190.0  8.014669e+08       False  L23328064   \n",
      "1            Tangerang    39893.0  6.011077e+08       False  L23328040   \n",
      "2               Bekasi    73137.0  1.102028e+09        True  L23322495   \n",
      "3               Badung   229384.0  3.456358e+09       False  L23214599   \n",
      "4      Jakarta Selatan   265952.0  4.007365e+09        True  L23321427   \n",
      "...                ...        ...           ...         ...        ...   \n",
      "10944    Jakarta Timur   997321.0  1.502763e+10        True  L20097799   \n",
      "10945           Bekasi    86434.0  1.302388e+09       False  L20099798   \n",
      "10946          Bandung   365684.0  5.510127e+09       False  L20046871   \n",
      "10947          Bandung   365684.0  5.510127e+09       False  L20046920   \n",
      "10948       Yogyakarta   312494.0  4.708660e+09       False  L20002852   \n",
      "\n",
      "       building_size  land_size   certificate  bedroom  bathroom  carport  \\\n",
      "0               50.0        NaN   Hak Lainnya      3.0       2.0      NaN   \n",
      "1               24.0        NaN  SHM/Freehold      NaN       1.0      NaN   \n",
      "2                NaN    44812.0  SHM/Freehold      2.0       1.0      NaN   \n",
      "3              134.0        NaN     Leasehold      1.0       1.0      NaN   \n",
      "4              137.0      137.0  SHM/Freehold      3.0       2.0      NaN   \n",
      "...              ...        ...           ...      ...       ...      ...   \n",
      "10944         1400.0      859.0  SHM/Freehold      NaN       NaN      NaN   \n",
      "10945           80.0       40.0           HGB      NaN       NaN      NaN   \n",
      "10946            NaN     5148.0  SHM/Freehold      NaN       NaN      NaN   \n",
      "10947            NaN     5148.0  SHM/Freehold      NaN       NaN      NaN   \n",
      "10948          244.0      106.0  SHM/Freehold      NaN       NaN      NaN   \n",
      "\n",
      "                     realtor                  realtor_office        contact  \n",
      "0            Merry Christina  Ray White Bintaro Trade Center  6287771888727  \n",
      "1             Rifia Nurdiana  Ray White Bintaro Trade Center   628170090100  \n",
      "2      Bertha Erlinda Sujati              Ray White Cikarang   622139715999  \n",
      "3      Eunike. Berlianne A.S                Ray White Canggu  6282145053818  \n",
      "4             Octavia Sylvie           Ray White CBD Jakarta  6282110611160  \n",
      "...                      ...                             ...            ...  \n",
      "10944         Kuncoro Widodo               Ray White Menteng  6281345268155  \n",
      "10945    Wahyu Putra Pribadi              Ray White Cikarang  6281219135665  \n",
      "10946          Christian Shu              Ray White Sukajadi  6281222122618  \n",
      "10947          Christian Shu              Ray White Sukajadi  6281222122618  \n",
      "10948                 ANNA P         Ray White Central Jogja  6281514220380  \n",
      "\n",
      "[10947 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "# Melakukan merge dari berkas JSON cadangan untuk membuat berkas JSON dan CSV (untuk redundancy) gabungan\n",
    "# Dibuat apabila terjadi kegagalan koneksi di sesi scraping\n",
    "\n",
    "json_dir = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\data'  \n",
    "csv_dir = r'C:\\Users\\Haidar\\OneDrive - Institut Teknologi Bandung\\Desktop\\github\\Seleksi-2023-Tugas-1\\Data Scraping\\src\\csv'\n",
    "df_list = []\n",
    "\n",
    "json_counter = 0\n",
    "\n",
    "for file in os.listdir(json_dir):\n",
    "    if file.endswith('.json'):\n",
    "        json_counter += 1\n",
    "        json_path = os.path.join(json_dir, file)\n",
    "        with open(json_path, 'r') as f:\n",
    "            json_data = f.read()\n",
    "\n",
    "        df_temp = pd.read_json(json_data)\n",
    "        df_list.append(df_temp)\n",
    "\n",
    "df_merged = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
    "\n",
    "json_filename = os.path.join(json_dir, f'raywhite_merged.json')\n",
    "csv_filename = os.path.join(output_dir_csv, f'raywhite_merged.csv')\n",
    "\n",
    "df_merged.to_json(json_filename, orient='records')\n",
    "df_merged.to_csv(csv_filename, index=False)\n",
    "\n",
    "print('Proses merging JSON telah selesai!\\n')\n",
    "\n",
    "print(f'Dokumentasi:')\n",
    "print('Banyak JSON cadangan yang dihasilkan: ', json_counter)\n",
    "print('Banyak entry valid valid di dataframe akhir: ', len(df_merged) - 1)\n",
    "print('Persentase entry yang valid: '+str(((len(df_merged) - 1) / (json_counter * 585)) * 100)+'%')\n",
    "\n",
    "print(f\"\\nHasil scraping telah diubah menjadi dataframe dan disimpan di:\\n{csv_filename}\\n{json_filename}\\n\")\n",
    "\n",
    "print('Dataframe gabungan:\\n')\n",
    "print(df_merged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
